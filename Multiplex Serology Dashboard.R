###    STARTUP STUFF    ##################################################################

#The code below must be manually run before the app 
## START OF REQUIRED CODE ##########
list.of.packages <- c("shiny","shinyBS","shinyjs","shinydashboardPlus","MazamaCoreUtils",
                      "openxlsx","plyr","dplyr","tidyr","magrittr","stringr","data.table",
                      "ggplot2","plotly","shinycssloaders","logging","rstudioapi")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
## END OF REQUIRED CODE ##########

lapply(list.of.packages, require, character.only = TRUE)

# Sets the working directory to the current directory
setwd(dirname(rstudioapi::getSourceEditorContext()$path))
tmpDir <- getwd()

# Used for debugging. Errors will be saved to the files below. Can set the debugging level to different levels.
# 
  logger.setup(
    errorLog = file.path(tmpDir,"ERROR.log"),
    warnLog = file.path(tmpDir,"WARN.log"),
    infoLog = file.path(tmpDir,"INFO.log"),
    debugLog = file.path(tmpDir,"DEBUG.log"),
    traceLog = file.path(tmpDir,"TRACE.log")
  )
logger.setLevel(DEBUG)
logger.setLevel(TRACE)

logger.info("Logger Successfully loaded")

# Prevents the CSVs and other files from importing everything as factors
options(stringsAsFactors = F)

#Default values for options
numControls <- 4
beadcountCutoffs <- "80,100,300,500" #Number below [1], between [1] and [2], and above [3] will be flagged as warnings
GSTcutoff <- 100
rowMeanFactorCutoff <- 2

###    UI    #########################################################################
# 
ui <- tagList(useShinyjs(),navbarPage(  "Multiplex Serology v1.0",
  tabPanel("SAS1",
  # Sidebar layout with input and output definitions 
  sidebarLayout(
    
    # Sidebar panel for inputs 
    sidebarPanel(

      # Input: The CSV files generated by the Luminex machines
      
      fileInput("luminexDataFI", "Choose Luminex Files",
                multiple = TRUE,
                buttonLabel=">"
      ),
      
      # Input: The allocation plan with the FortNr to ID data
      fluidRow(column(
        7,
        
        fileInput("allocationPlanFI", "Choose Allocation Plan", 
                  multiple = FALSE, buttonLabel = ">"
        )
      ),
      column(
        5,
        # Input: The worksheet selection; is disabled until the file is uploaded
        disabled(selectInput("allocationWorksheetsSI",
                             h3("Worksheet"),
                             choices = "", ))
      )),
      
      fluidRow(column(
        7,
        
        # Input: The bead list data. TODO: actually make this do something
        fileInput("beadListFI",
                  "Choose Bead List",
                  multiple = FALSE,
                  buttonLabel = ">")
      ),
      column(
        5,
        # Input: The worksheet selection; is disabled until the file is uploaded
        disabled(
          selectInput("beadListWorksheetsSI",
                      h3("Worksheet"),
                      choices = "", ))
      )
      ),
      # Collapsable box containing the options
      bsCollapse(id = "parameterBox",
                bsCollapsePanel("Options", 
                    numericInput("controlNumber", h3("Number of Controls"), value = numControls), 
                    numericInput("gstCutoff",  h3("GST Cutoff"),  value = GSTcutoff),
                    numericInput("rowMeanFactor", h3("Row Mean Cutoff Factor"), value = rowMeanFactorCutoff),
                    textInput("beadCountCutoffs", label = h3("Bead count cutoffs"), value = beadcountCutoffs),
                style = "default")
      ),
      # Input: Buttons for running the script
        actionButton("startSAS1Analysis", "Start Analysis"),
        disabled(actionButton("generateSAS1xlsx","Export Excel File")),
      width = 3
    ),
 
    # Main panel for displaying outputs 
    mainPanel(
      tabsetPanel(type = "tabs",
                  
                  tabPanel("Bead count", withSpinner(plotlyOutput("SAS1plot",height = '700px'))),
                  tabPanel("MFI", withSpinner(plotlyOutput("SAS1MFIplot",height = '700px'))))
    ))),
    # Tab for running SAS2
    tabPanel("SAS2",
             sidebarLayout(
             sidebarPanel(
               # Input: Select a file 
               fileInput("SAS1input", "Choose SAS1 output XLSX",
                         multiple = FALSE,
               ),      
               # Collapsable box containing the options
               bsCollapse(id = "parameterBoxSAS2",
                                 bsCollapsePanel("Options", 
                                                 checkboxInput("netNegative", label = "Net negative values", value = FALSE),
                          checkboxInput("showSteps", label = "Show step-wise calculations", value = FALSE))
               ),
               
               # Input: Buttons for running the script
               actionButton("startSAS2Analysis", "Start Analysis"),
               disabled(actionButton("generateSAS2xlsx","Export Excel File")),
               width = 3
             ),
             mainPanel(
               
               withSpinner(plotlyOutput("SAS2plot",height = '700px'))
               
             )
        )
    )
)
,
# The CSS styles. Could use a seperate file and load via includeCSS("styles.css") instead, but this
# will keep it as a single file
singleton(tags$head(HTML("

<style type='text/css'>

.form-group.shiny-input-container {
    padding-top: 5px;
}


.form-group {
            margin: 0 !important;
          }
h3 {
  color: black;
  margin: 3px;
  font-size: 12px
}

.well {
	padding:5px
	
}
.progress {
	margin-bottom:5px
	
}

hr {
	margin:3px
	
}

col-sm-4 {
	padding-right:0px
	padding-left:0px
}

.btn.disabled {
	background-color: #eeeeee
}

</style>")))
)

###    SERVER    #########################################################################
# Define server logic required to draw a histogram
server <- function(input, output, session) {
  
  options(shiny.maxRequestSize=30*1024^2) # fixes file input size limitation
  
  observeEvent(input$luminexDataFI, {
    
    logger.debug("Luminex data files observer triggered")

  })
  
  # Enables the allocation plan worksheet selection after an event has occured (should be the file input)
  observeEvent(input$allocationPlanFI, {
    logger.debug("Allocation Plan observer triggered")
    enable("allocationWorksheetsSI")
    
  })
  # Reactive variable - will change UI stuff when an event occurs
  allocationWorksheets = reactive({
    #Gets the file from the file input
    inputFile <- input$allocationPlanFI
    # Not sure how null is thrown there, but 
    if (!is.null(inputFile)) {
      getSheetNames(inputFile$datapath)
    }
  })
  
  #Updates the selection box for the allocation worksheet with the sheets contained in the file
  observe({
    updateSelectInput(session, "allocationWorksheetsSI",
                      choices = allocationWorksheets(),)
  })
  
  # Enables the beadlist worksheet selection after an event has occured (should be the file input)
  observeEvent(input$beadListFI, {
    
    logger.debug("Bead list observer triggered")
    enable("beadListWorksheetsSI")

  })
  # Reactive variable - will change UI stuff when an event occurs
  beadListWorksheets = reactive({
    inputFile <- input$beadListFI
    
    if (!is.null(inputFile)) {
      getSheetNames(inputFile$datapath)
    }
  })
  
  #Updates the selection box for the bead list worksheet with the sheets contained in the file
    observe({
    updateSelectInput(session, "beadListWorksheetsSI",
                      choices = beadListWorksheets(),)
  })
  
  # The button press for start analysis of SAS1
  observeEvent(input$startSAS1Analysis, {

    # TODO: add in checks for each of the file inputs
    # Get the datapaths for the CSVs
    plateDataDF <<- input$luminexDataFI
    
    # Get the DF for the allocation plan
    infile <- input$allocationPlanFI
    insheet <- input$allocationWorksheetsSI
    allocationPlanDF <<-
      read.xlsx(infile$datapath, sheet = insheet, colNames = TRUE)
    
    # Get the DF for the bead list
    infile <- input$beadListFI
    insheet <- input$beadListWorksheetsSI
    beadListDF <-
      read.xlsx(infile$datapath, sheet = insheet, colNames = TRUE, startRow=1)
    
    logger.debug("Start analysis observer triggered")
    
    #Show the pop-up to display while the script it running
    showModal(modalDialog("Generating multiplex serology analysis...", footer=NULL))
    SAS1DF <<- SAS1(plateDataDF, allocationPlanDF, beadListDF)
    
    # Stores function return as SAS1graph (looks weird due to SHINY syntax and reactiveVal)
    SAS1graph(getCountGraph(SAS1DF))
    SAS1MFIgraph(getMFIgraph(SAS1DF))

    # Remove the pop-up
    removeModal()
    
    #Enables the button to generate the XLSX
    enable("generateSAS1xlsx")
  })
  
  #Allows dynamic updating of the content
  SAS1MFIgraph <- reactiveVal()
  
  # Will display the plot once SAS1graph has a value stored in it
  output$SAS1MFIplot <- renderPlotly({
    if (is.null(SAS1MFIgraph())) return()
    ggplotly(SAS1MFIgraph(),hovertemplate="booooo")
  })
  
  
  
  #Allows dynamic updating of the content
  SAS1graph <- reactiveVal()
  
  # Will display the plot once SAS1graph has a value stored in it
  output$SAS1plot <- renderPlotly({
    if (is.null(SAS1graph())) return()
    ggplotly(SAS1graph(),hovertemplate="booooo")
  })
    
  
  # Button press to generate the formatted XLSX file
  observeEvent(input$generateSAS1xlsx, {
    
    #Show the popup to display during analysis
    showModal(modalDialog("Generating Excel output...", footer=NULL))
    
    #Generates the XLSX file
    exportSAS1DFtoFormattedExcel(SAS1DF,"SAS1")
    
    #Opens Excel with the created file
    shell.exec("SAS1.xlsx")
    
    #Remove the popup
    removeModal()
    
  })
  
  # The button press for starting the SAS2 analysis
  observeEvent(input$startSAS2Analysis, {
    
    logger.debug("SAS1 input observer triggered")

    # Show the pop-up saying the scripts are runnsing
    showModal(modalDialog("Calculating background and control data...", footer=NULL))
    
    # Get the SAS1 output file
    infile <- input$SAS1input
    SAS1DF <- importSAS1xlsxtoDF(infile$datapath)
    
    netNegative <- input$netNegative # Check if net negative values are desired
    
    # Generate the DF for the SAS2 analysis
    SAS2DF <<- SAS2(SAS1DF,netNegative)
    
    # Stores function return as SAS1graph (looks weird due to SHINY syntax and reactiveVal)
    SAS2graph(getMFIgraph(SAS2DF[[1]]))
    
    #Enable the export button
    enable("generateSAS2xlsx")
    
    # Remove the popup
    removeModal()
  })
  
  # Button press for export the SAS2 graph
  observeEvent(input$generateSAS2xlsx, {
    
    showModal(modalDialog("Generating Excel output...", footer=NULL))
    showSteps <- input$showSteps # Check if the individual calculations are dsired
    exportSAS2DFtoFormattedExcel(SAS2DF, showSteps, "SAS2")
    shell.exec("SAS2.xlsx")
    removeModal()
    
  })
  
  #Allows dynamic updating of the content
  SAS2graph <- reactiveVal()
  
  # Will display the plot once SAS2graph has a value stored in it
  output$SAS2plot <- renderPlotly({
    if (is.null(SAS2graph())) return()
    ggplotly(SAS2graph())
  })
}

###    ANALYSIS    #######################################################################################
# A hard coded version of the software. Functions almost like SAS

analysisDebugStart <- function() {
  
  # Get the file paths
  allocationPlanPath = "U:\\sensitive\\Sero Projekte\\Studenten\\Andrew\\CKB (Safe test)\\Plattenbelegungfinal.xlsx"
  beadListPath = "U:\\sensitive\\Sero Projekte\\Studenten\\Andrew\\CKB (Safe test)\\Beads und Antigene.xlsx"
  plateFilesPath = "U:\\sensitive\\Sero Projekte\\Studenten\\Andrew\\CKB (Safe test)\\Bad CSV"
  
  #Set the Sheet/Range of the data
  beadListSheet <- "Beads_Antigene_sortednachBeads"
  beadListRange <- "K4:K50"
  allocationPlanSheet <- "Tabelle1"
  
  # Generate the dataframes
  allocationPlanDF <<- read.xlsx(allocationPlanPath, sheet=allocationPlanSheet, colNames=TRUE)
  beadListDF <- read.xlsx(beadListPath,sheet = beadListSheet,colNames = TRUE)
  platePathDF <- data.table(
    name = list.files(plateFilesPath),
    datapath = list.files(plateFilesPath, full.names = TRUE)
  )
  
  SAS1(platePathDF,allocationPlanDF,beadListDF)
}

###    SAS1    #######################################################################################

# Function that performs the same operations as SAS1
# Import the raw .CSV, allocation plan and bead list, then compiles and merges the data based around
# the fortNr definied in the allocation plan
#
#   platePathDF - the DF containing the information from each plate (filename and path, primarily)
#   allocationPlanDF - the DF containing the individual sera allocation data
#   beadListDF - the name and beadsort for each of the antigens
SAS1 <- function(platePathDF, allocationPlanDF, beadListDF) {
  
  logger.debug("Analysis started")
  
  # Get data from the filename of each plate CSV
  platePathDF <- scrapePlatePathDF(platePathDF)
  
  # Compile the Luminex data and bead count data from the plate CSV
  compiledLuminexDF <- importPlateData(platePathDF)
  
  # Add the remeasurements
  compiledLuminexDF <- addRemeasurements(platePathDF, compiledLuminexDF)
  
  # Add the antigen names based on the beadlist
  compiledLuminexDF %<>% addAntigenNames(beadListDF)
  
  # Merge with the allocation plate data
  allocatedLuminexDF <- addAllocationData(compiledLuminexDF, allocationPlanDF)

  # Find warning critera
  filteredLuminedDF <- generateLuminexWarnings(allocatedLuminexDF)
  
  return(filteredLuminedDF)

}

# Scrape the filename of the plates in the CSV folder for the luminex machine, plate number and
# remeasuremennt status. 
#
# platePathDF - the data frame with the file information from the plates. Must have the
#               a column for filename (called 'name') and datapath (called 'datapath')
#
# returns - the dataframe with the scraped data added to it (luminexMachine, plateNumber, remeasurement status)
scrapePlatePathDF <- function(platePathDF) {
  
  
  logger.debug("Scraping plate filenames for data")
  
  # Add necessary columns to plate path data, for some reason using NULL was throwing errors
  # Uses cbind to move the new variable to the left (for easier debugging)
  platePathDF <- cbind(numSamples = -1, platePathDF)
  platePathDF <- cbind(remeasurement = "X", platePathDF)
  platePathDF <- cbind(plateNumber = -1, platePathDF)
  platePathDF <- cbind(luminexMachine = "X", platePathDF)
  
  #iterate through the data files and extract the extract luminex machine, plate numbers, and remeasurements
  # Must be in the format 'Luminex [A:E] Platte [1:999] [Remeasurement]
  # Remeasurement can be any word or charactor
  for (i in 1:nrow(platePathDF)) {
    
    # Regex the filename
    nameData <- str_match(platePathDF[i,]$name, "(.*?)Luminex ([A, B, C, D, E]) Platte (\\d{1,3})\\s?(.*)?.csv")
    platePathDF[i,]$luminexMachine <- luminexMachine <- nameData[,3]
    platePathDF[i,]$plateNumber <- plateNumber <- strtoi(nameData[,4])
    platePathDF[i,]$remeasurement <- remeasurement <- nameData[,5]
    logger.trace(paste("   Found plate",luminexMachine,plateNumber,remeasurement,sep=" "))
  }
  
  logger.debug(paste("   Parsed through files:",nrow(platePathDF)))
 
  return (platePathDF)
  
}

# Takes the data from the plate path, imports each plate and read the Luminex and bead count data
#
# platePathDF - the data frame with the file information from the plates. See scrapePlatePathDF for format
#
# returns - the dataframe with the FortNr, Luminex and bead count data, and all other respective columns
importPlateData <- function(platePathDF) {
  

  logger.debug("Compiling Luminex data from plates")
  
  #iterate through the non-remeasurements files and merge data
  platesProcessed <- 0
  
  for (i in 1:nrow(platePathDF)) {
    
    # Skip if remeasurment
    if (platePathDF[i,]$remeasurement != "") {
      #logger.trace("Found remeasurement, skipping")
      next;
    }
    
    luminexDF <- getLuminexAndBeadCountData(platePathDF,i)
    # 
    # # add whether the measurement is a sample or control
    # samplesDF <- tail(luminexDF, n=numControls)
    # luminexDF$Sample[match(samplesDF$FortNr, luminexDF$FortNr)] <- "Control"
    
    # Merge Luminex data with other plates, and create new data frame if it's the first plate
    if(platesProcessed == 0) {
      compiledLuminexDF <- luminexDF[FALSE,]
    }
    compiledLuminexDF <- rbind(compiledLuminexDF,luminexDF)
    
    # Count the plate as done
    platesProcessed <- platesProcessed + 1
  }
  
  logger.debug(paste("Processed Luminex data:"))
  logger.debug(paste("   Plates:", platesProcessed))
  logger.debug(paste("   Wells:", nrow(compiledLuminexDF)))
  
  return(compiledLuminexDF)
}

#Add the remeasurements to the dataframe obtained from importPlateData
#
# platePathDF - the data frame with the file information from the plates. See scrapePlatePathDF for format
# compiledLuminexDF - the data frame obtained from importPlateData
# TODO: Wrap this into the getLuminexAndBeadCountData
#
# returns - the same dataframe as importPlateData, except with the remeasurements overwriting respectively
addRemeasurements <- function(platePathDF, compiledLuminexDF) {
  

  
  logger.debug("Adding in the remeasurement data")
  
  #iterate through the non-remeasurements files and merge data
  remeasurementsProcessed <- 0
  for (i in 1:nrow(platePathDF)) {
    
    index <- 0

    # Skip if remeasurment
    if (platePathDF[i,]$remeasurement == "") {
      #logger.trace("Found non-remeasurement, skipping")
      next;
    }
    
    luminexDF <- getLuminexAndBeadCountData(platePathDF,i)
    
    logger.trace(paste("Found remeasurement:",luminexDF$luminexMachine,luminexDF$plateNumber, luminexDF$Location))  
    
    #Replace the old measurements with the remeasurements
    compiledLuminexDF <- overwriteByFortNr(compiledLuminexDF, luminexDF)
    
    remeasurementsProcessed <- remeasurementsProcessed + 1
    
  }
  
  logger.debug("Processed remeasurements:")
  logger.debug(paste("   Remeasurements:", remeasurementsProcessed))
  
  return(compiledLuminexDF)
}

# Add the antigen names to the _## columns for the MFI and bead count measurements
#   compiledLuminexDF - the DF to append the frame to
#   beadlistDF - the DF for the bead names
# TODO: make this match by value in 'beadsort' rather than by vector index matching to prevent mismatches if a bead is missin

addAntigenNames <- function(compiledLuminexDF, beadListDF) {
  
  # Get the columns for MFI and Count
  mfiCols <- getColNameContaining(compiledLuminexDF,"mfi_")
  countCols <- getColNameContaining(compiledLuminexDF,"count_")
  
  # Get the beadnames
  beadCols <- beadListDF$Name
  
  # Combine the names with a ";" seperating
  concatCols <- paste(mfiCols, beadCols,sep="; ")
  setnames(compiledLuminexDF, old = mfiCols, new = concatCols)
  
  concatCols <- paste(countCols, beadCols,sep="; ")
  setnames(compiledLuminexDF, old = countCols, new = concatCols)
  
  # Rename the columns in the DF
  
  return (compiledLuminexDF)
  
}

# Helper function to parse the individual Luminex CSV files for measurements and bead counts
# 
# platePathDF - the data frame with the file information from the plates. See scrapePlatePathDF for format
# i - the iteration number of the loop. Could be removed if only the row from the platePathDF was passed above
# 
# return - the compiledLuminex DF (Luminex and bead counts)
getLuminexAndBeadCountData <- function(platePathDF,i) {
  
  sampleDF <- read.csv(platePathDF[i,]$datapath, sep=';', header=FALSE, skip=20,nrows=1)
  numSamples <- platePathDF[i,]$numSamples <- sampleDF[,2]
  
  # read Luminex data from the CSV file
  luminexDF <- read.csv(platePathDF[i,]$datapath, sep=';', header=TRUE, skip=25,nrows=numSamples,dec=",")
  
  # remove the leading X from bead column numbers, and prefix with 'mfi_' 
  luminexDF <- prefixInvalidCols(luminexDF, "mfi")
  
  #add the extraction information from filename to new columns (line 26 on, inc headers)
  #luminexDF$Sample = "Sample" # Will differentiate from controls down below
  luminexDF <- cbind(plateNumber = platePathDF[i,]$plateNumber, luminexDF)
  luminexDF <- cbind(luminexMachine = platePathDF[i,]$luminexMachine, luminexDF)
  
  # read the bead count data from the CSV file (need to take into account the skip offset from median and result sections in xlsx)
  beadCountDF <- read.csv(platePathDF[i,]$datapath, sep=';', header=TRUE, skip=(223-2*(96-numSamples)),nrows=numSamples,dec=",")
  # remove the leading X from bead column numbers, and prefix with 'count_' 
  beadCountDF <- prefixInvalidCols(beadCountDF, "count")
  
  # add the unique FortNr to each line based on row and plate number
  FortNr <- getFortNr(platePathDF[i,]$plateNumber,luminexDF$Location)
  luminexDF  <- cbind(FortNr, luminexDF)
  
  FortNr <- getFortNr(platePathDF[i,]$plateNumber,beadCountDF$Location)
  beadCountDF <- cbind(FortNr, beadCountDF)
  
  #Drop Sample and Location from beadCountDF, or it will cause problems later
  beadCountDF <- beadCountDF[ , !(names(beadCountDF) %in% c("Sample","Location"))]
  
  # merge the luminex data and bead count DFs together
  luminexDF <- merge(luminexDF,beadCountDF, by="FortNr")
  
  logger.trace(paste("Found",nrow(luminexDF),"readings from",head(FortNr,n=1),"to",tail(FortNr,n=1),"on plate",platePathDF[i,]$plateNumber))
  
  return(luminexDF)
}


# Merges in the allocation data (ID, etc) to the compiledLuminexDF
#
# compiledLuminexDF - the data frame obtained from importPlateData (including remeasurements)
# allocationPlanDF - the df for the respected Excel doc that includes all of the well information
#
# returns - the compiled, allocated Luminex DF
addAllocationData <- function (compiledLuminexDF, allocationPlanDF) {

  
  logger.debug("Starting to merge allocation plan to Luminex data")
  
  #Round all of the data values in compiledLuminexDF (better compatibilty with Excel/spreadsheets)
  compiledLuminexDF <- compiledLuminexDF %>% mutate_if(is.numeric, floor)
  
  # Merge the allocation plan, bead count data and luminex data based on FortNr
  allocatedLuminexDF <- merge(compiledLuminexDF,allocationPlanDF, by="FortNr")
  
  logger.debug("Luminex data allocated:")
  logger.debug(paste("   Entries:", nrow(allocatedLuminexDF)))
  
  return (allocatedLuminexDF)
}

# Generates warnings for low/high beadcounts and comments for SAS1
# Parses the beadcounts for < 80 and > 500, and looks for any columns containing the word 'comment',
# then pastes them together in a column called 'Warning'. Multiple warnings will be seperated by a semi-colon
#   df - the dataframe to add warnings to
generateLuminexWarnings <- function(df) {

  
  # Get all cols with prefix count
  cols <- names(select(df,contains("count")))
  
  # Add warnings where beadcount < 80, > 500, or the wells are empty
  # TODO: Get the counts from the options string instead of hardcoded
  cutoffs <- strsplit(beadcountCutoffs, ",")
  df %<>% addWarning(rowSums(df[,cols] < 80) %in% 1,"Count < 80")
  df %<>% addWarning(rowSums(df[,cols] > 500) %in% 1,"Count > 500")
  # df %<>% addWarning(rowSums(df[,cols] < cutoffs[1]) %in% 1,paste("Count < ",cutoffs[1]))
  # df %<>% addWarning(rowSums(df[,cols] > cutoffs[4]) %in% 1,paste("Count >",cutoffs[4]))
  df %<>% addWarning(tolower(df$ID) == "empty" | tolower(df$ID) == "leer","Empty")
  
  # Get missing total events column (indicates that a beadset was not counted)
  # TODO: Fix this
  # index <- which(df$ID == "empty" | df$ID == "leer")
  # df[index,]$Warning <- paste2(df[index,]$Warning,"Beadset missing (GST too high)") 
  
  # Get warning and comment columns
  cols <- c("Warning",names(select(df,contains("comment"))))
  # Paste comments to the warning column
  df$Warning <- apply( df[ , cols ] , 1 , paste2 , collapse = "; " )
  
  return(df)
}

# Exports the generated DF from SAS1 to a formatted Excel file
#   allocatedLuminexDF - the data frame to export
#   name - the name to save the Excel file as in the working directory
exportSAS1DFtoFormattedExcel <- function(allocatedLuminexDF,name) {

  # Get the MFI data and remove the mfi prefix from the beads
  mfiDF <- select(allocatedLuminexDF,"FortNr", "luminexMachine", "plateNumber", "Location","Warning", contains("mfi_"))
  mfiDF <- removePrefixCols(mfiDF,"mfi")
  
  # Same as above, but with beadcount
  beadCountDF <- select(allocatedLuminexDF,"FortNr", "luminexMachine", "plateNumber", "Location","Warning" ,contains("count_"))
  beadCountDF <- removePrefixCols(beadCountDF,"count")
  
  #Get the allocation data (all minus the mfi_ and count_ cols)
  allocationDataDF <- select(allocatedLuminexDF,-contains("count_"))
  allocationDataDF <- select(allocationDataDF,-contains("mfi_"))
  
  # Get the rows which an error is present
  # TODO: Change order of columns so that Warnings are on the left. Rem: Warning might not be last column, so have to search and move
  excludedDF <- allocatedLuminexDF[which(!is.na(allocatedLuminexDF$Warning)), ]

  #Create the workbook
  options("openxlsx.halign" = "center","openxlsx.valign" = "center", wrapText = TRUE)
  wb <- createWorkbook(name)
  
  # Add the sheets to the workbook
  addDataToWB(wb,"MFI",mfiDF)
  addDataToWB(wb,"Bead Count",beadCountDF)
  addDataToWB(wb,"Allocation Data",allocationDataDF)
  addDataToWB(wb,"Excluded",excludedDF)

  #Save the book
  saveWorkbook(wb, paste(name,".xlsx", sep=''), overwrite = TRUE)
}

# Imports an SAS1 generated XLSX back into R
#    xlsxlPath - path to the XLSX document
importSAS1xlsxtoDF <- function(xlsxPath) {

  allocationPlanDF <- read.xlsx(xlsxPath, sheet="Allocation Data", colNames=TRUE)
  mfiDF <- read.xlsx(xlsxPath, sheet="MFI", colNames=TRUE)
  mfiDF <- addPrefixCols(mfiDF,"mfi")

  # Merge the mfi data and allocation plan using the first five columns
  # This will ignore any of the lines deleted from either file
  # TODO: put a column for exclude so the data stays on the sheet, but not included in analysis
  mergeCols <- c("FortNr","luminexMachine","plateNumber","Location")
  allocatedLuminexDF <- merge(mfiDF,allocationPlanDF, by=mergeCols)
  
  # Bead count not used at all
  # beadCountDF <<- read.xlsx(xlsxPath, sheet="Bead Count", colNames=TRUE)
  # beadCountDF <- addPrefixCols(beadCountDF,"count")
  # allocatedLuminexDF <- merge(mfiDF,beadCountDF, by=mergeCols)
  # allocatedLuminexDF <- merge(allocatedLuminexDF,allocationPlanDF, by=mergeCols)

  allocatedLuminexDF$Excluded <- FALSE
  
  excludedDF <- read.xlsx(xlsxPath, sheet="Excluded", colNames=TRUE)

  excludedFortNr <- excludedDF[ , "FortNr"]
  
  allocatedLuminexDF[allocatedLuminexDF$FortNr %in% excludedFortNr,]$Excluded <- TRUE
  
  allocatedLuminexDF <- allocatedLuminexDF[order(allocatedLuminexDF$FortNr),]
  
  return(allocatedLuminexDF)
}

###    SAS2    #######################################################################################

# Function that performs the same operations as SAS2
# Remove the background, GST, and Luminex correction from the MFI values given by the Luminex machines
#
#   allocatedLuminedDF - The output from SAS1
#   netNegative - flag for it the user desires the net negative values be outputted
# 
#   @return - Multiple DFs with the net MFI being first, then raw, background subtracted, GST subtracted, then Luminex correction
SAS2 <- function (allocatedLuminexDF, netNegative=FALSE) {

  logger.debug("Getting row means and sum for Luminex data")
  
  # Calculate the row mean and row sum for beads
  allocatedLuminexDF$rowMean <- round(rowMeans(select(allocatedLuminexDF, starts_with("mfi_"))));
  allocatedLuminexDF$rowSum <- round(rowSums(select(allocatedLuminexDF, starts_with("mfi_"))));

  # get the controls (typically the last n (usually 4, wells 94-96) wells of the plate)
  plateControlDF <- allocatedLuminexDF %>% group_by(luminexMachine,plateNumber) %>% do(tail(.,n=numControls)) %>% ungroup()
  plateControlDF$Sample <- "Control"
  
  # get the seras 
  seraDF <- anti_join(allocatedLuminexDF, plateControlDF, by = "FortNr")
  seraDF$Sample <- "Sample"
  
  # get all the empty (blank) wells for background removal
  # slice(which.min(Position) takes first well of the controls to find the blank (always first in controls)
  emptyControlDF <- plateControlDF %>% group_by(luminexMachine,plateNumber) %>% slice(which.min(Position)) %>% ungroup()
  
  #Remove the excluded measurements from the blank control wells before calculating the blank mean
  emptyControlDF %<>% subset(Excluded == FALSE)
  emptyControlDF %<>% within(rm("Excluded"))
  
  # remove the anti-tag wells (uses mode to filter out blank)
  antitagDF <- subset(emptyControlDF, tolower(ID) != Mode(tolower(ID)))
  plateControlDF <- anti_join(plateControlDF, antitagDF, by = "FortNr")
  
  # takes the mode of the empty/blank wells (assumes that there are more empty/blank wells than anti-tag wells)
  emptyControlDF %<>% subset(tolower(ID) == Mode(tolower(ID)))
  
  # calculate the means for all the empty wells; cols re-used for below as they are all the MFI cols
  emptyMeans <- round(colMeans(emptyControlDF[,getColNameContaining(emptyControlDF, "mfi")]))
 #emptyMeans <- round(colMeans(emptyControlDF[ , grepl( "mfi_" , names( emptyControlDF ) ) ]))
  mfiCols <- names(emptyMeans)
  
  #bind the sera and control DFs together (will seperate after operations)
  seraControlDF <- rbind(seraDF,plateControlDF)

  #Remove the excluded values (flagged from the SAS1 input)
  seraControlDF %<>% subset(Excluded == FALSE)
  seraControlDF %<>% within(rm("Excluded"))
  
  logger.debug("Removing empty well control value")
  
  # Save values for debug mode
  rawDF <- seraControlDF
  
  #Substract the empty means from all the raw MFI values
  seraControlDF[mfiCols] <- data.frame(t(apply(seraControlDF[mfiCols],1,'-',emptyMeans)))
  
  # Save values for debug mode
  subBGDF <- seraControlDF
  
  logger.debug("Removing GST values")

  #Subtract the GST values for the sera and controls, except for the last column (GST will always be 1 otherwise)
  seraControlDF[head(mfiCols,n=length(mfiCols)-1)] <- 
    seraControlDF[head(mfiCols,n=length(mfiCols)-1)] - seraControlDF[mfiCols][,ncol(seraControlDF[mfiCols])] 
  
  # Save values for debug mode
  subGSTDF <- seraControlDF
  
  #Set all elements to minimum value of 1 if netNegative is FALSE 
  if (netNegative == FALSE) {
    seraControlDF[mfiCols] = apply(seraControlDF[mfiCols], MARGIN = c(1,2), FUN = function(x) max(x,1) )
  }
  
  #Add the antitag values
  seraControlDF %<>% rbind(antitagDF)
  rawDF %<>% rbind(antitagDF)
  subBGDF %<>% rbind(antitagDF)
  subGSTDF %<>% rbind(antitagDF)
  
  logger.debug("Adding correction factors for each Luminex machine")
  #Add the correction factors for Luminex machines (B,D*1.1)
  #Could edit this directly instead of subsetting (faster)
  luminexDnB <- subset(seraControlDF, luminexMachine=="B" | luminexMachine=="D")
  luminexDnB[mfiCols] = round(luminexDnB[mfiCols]*1.1)
  seraControlDF <- overwriteByFortNr(seraControlDF,luminexDnB)

  # Add the warnings for when row mean < 2 * empty mean
  emptyMean <- mean(emptyMeans)
  seraControlDF %<>% addWarning(seraControlDF["rowMean"] < emptyMean*rowMeanFactorCutoff, 
                                paste("Row mean < Empty Mean *",rowMeanFactorCutoff))
  
  # Add warnings for when GST > 100
  seraControlDF %<>% addWarning(seraControlDF[tail(mfiCols,n=1)] > GSTcutoff, "GST > 100") #TODo: fix the number
  
  # Save values for debug mode
  subCorrDF <- seraControlDF
  
  #Sort all of the data by the FortNr
  seraControlDF <- orderFortNr(seraControlDF)
  rawDF <- orderFortNr(rawDF)
  subBGDF <- orderFortNr(subBGDF)
  subGSTDF <- orderFortNr(subGSTDF)
  subCorrDF <- orderFortNr(subCorrDF)

  logger.debug("Analysis completed")
  
  return(list(seraControlDF,rawDF,subBGDF,subGSTDF,subCorrDF))

}

# Exports the generated DF from SAS2 to a formatted Excel file
#   seraControlList - the data frame to export. This is a list of 5 DF showing step-wise calculations. Actual net MFI is in [1].
#   showSteps - flag to determine whether to include the individual step measurements
#   name - the name to save the Excel file as in the working directory
exportSAS2DFtoFormattedExcel <- function(seraControlList,showSteps,name) {

  
  seraControlDF <- seraControlList[[1]]
  
  #Seperate the sera and control data
  seraDF <- subset(seraControlDF, Sample=="Sample")
  controlDF <- subset(seraControlDF, Sample=="Control")
  
  # Get the sera MFI data and remove the mfi prefix from the beads
  #seraDF <- select(seraDF,"FortNr", "plateNumber", "Location", "ID", "rowMean", "rowSum","Warning", contains("mfi_"))
  seraDF <- removePrefixCols(seraDF,"mfi")
  seraDF <- seraDF[order(seraDF$FortNr),]
  
  # Same as above, but with control
  #controlDF <- select(controlDF,"FortNr", "plateNumber", "Location", "ID", "rowMean", "rowSum","Warning", contains("mfi_"))
  controlDF <- removePrefixCols(controlDF,"mfi")
  controlDF <- controlDF[order(as.character(controlDF$ID)),]

  #Get the allocation data (all minus the mfi_ and count_ cols)
#  allocationDF <- select(seraControlDF,-contains("count_"))
 # allocationDF <- select(seraControlDF,-contains("mfi_"))
  
  #Create the workbook
  options("openxlsx.halign" = "center","openxlsx.valign" = "center", wrapText = TRUE)
  wb <- createWorkbook(name)
  
  if (showSteps == TRUE) {
    
    addDataToWB(wb,"Raw Luminex",seraControlList[[2]])
    addDataToWB(wb,"Minus BG",seraControlList[[3]])
    addDataToWB(wb,"Minus GST",seraControlList[[4]])
    addDataToWB(wb,"Machine Correction",seraControlList[[5]])
  }
  
  addDataToWB(wb,"Sera",seraDF)
  addDataToWB(wb,"Control",controlDF)
  #addDataToWB(wb,"Allocation Data",allocationDF)

  #Save the book
  saveWorkbook(wb, paste(name,".xlsx", sep=''), overwrite = TRUE)
}



###    UTILITY FUNCTIONS    #########################################################################

# Adds a warning to all of the indexes in the bools vector. 
#   df - the dataframe to add the warnings to
#   bools - a list of bools, where TRUE = rows you want to add the error to
#   str - the string to add to the warning
#
#   Usage: df %<>% addWarning(tolower(df$ID) == "empty","Empty")
#   Adds the warning "Empty" to all rows in df where the ID is 'empty' (case unspecific);
#   %<>% passes the dataframe to the warning, then stores the result back in df

addWarning <- function (df, bools, str) {

  #Create new column for warnings, if it doesn't exist
  if(!"Warning" %in% colnames(df)) {df$Warning <- NA}
  
  index <- which(bools)
  if (length(index) > 0) {df[index,]$Warning <- paste2(df[index,]$Warning,str)}
  
  return(df)
}



# Overwrite the original measurement data with the remeasurement data
# This is done by matching the FortNr between the two dataframes, and replacing all matching columns from remeasurementDF
# into allMeasurementDF
#   allMeasurementDF - the DF to search for the FortNr, and overwrite with the data in singleDF
#   remeasurementDF - the remeasurement DF that will overwrite the data in combinedDF
overwriteByFortNr <- function(allMeasurementDF, remeasurementDF) {
  
  allMeasurementDF[match(remeasurementDF$FortNr,allMeasurementDF$FortNr),names(remeasurementDF)] <- remeasurementDF

  return(allMeasurementDF)
}

# Returns all of the column names with a specified prefix
# Mainly used for finding the name of MFI and count data
#   df - the DF in which to get the names from
#   prefix - the string prefix to find
getColNameContaining <- function(df,prefix) {
  
  # df <- df[ , grepl( prefix , names( df ) ) ]
  return(names(select(df,contains(prefix))))
  
}

# Adds a prefix to all columns that start with an X or _ (R adds this automatically if the column starts with
#  a number). Strips the leading zeros that sometimes don't appear preceding the bead number to avoid errors
#   df - the DF to add the prefixes
#   prefix - the prefix to add
prefixInvalidCols <- function(df, prefix) {
  
  colnames(df) <- gsub("^(?:X|_)0*(\\d{1,3})", paste(prefix,"_\\1",sep=""), colnames(df))
  return (df)
  
}

# Removes a prefix to columns starting with "_"
# TODO replace this with a generic funcation that you can specify a start character
#
#   df - the dataframe with columns to remove the prefix from
#   prefix - the prefix to remove from the columns
removePrefixCols <-function(df, prefix) {
  colnames(df) <- gsub(paste(prefix,"(_\\d{1,3})",sep=""), paste("\\1",sep=""), colnames(df))
  return (df)
}

# Add a prefix to columns starting with "_"
# TODO replace this with a generic funcation that you can specify a start character
#   df - the dataframe with columns to add the prefix
#   prefix - the prefix to add to the columns
addPrefixCols <- function(df, prefix) {
  colnames(df) <- gsub(paste("(_\\d{1,3})",sep=""), paste(prefix,"\\1",sep=""), colnames(df))
  return (df)
}

# Gets the FortNr from the plate and location
# i.e. (1, "A1") converts to 1
#      (1,"H12") converts to 96
#      (2, "A1") converts to 97
getFortNr <- function(plateNumber, location) {
  
  return(96*(plateNumber-1) + positionToWell(location))
  
}

# Converts the string location to logical number
# i.e.  ("A1") converts to 1
#      ("H12") converts to 96
positionToWell <- function(location) {
  
  wellrow <- substring(location, first = 1, last = 1)
  wellcol <- substring(location, first = 2, last = 4)
  
  return (rowColToWell(wellrow, wellcol))
}

# Converts the row and column to logical number
# i.e.  rowColToWell("A","1") = 1
#       rowColToWell("C","5") = 29
#      rowColToWell("H","12") = 96
rowColToWell <- function(wellrow, wellcol) {
  
  utf <- lapply(as.matrix(wellrow),utf8ToInt)
  
  return ((as.numeric(utf)-64)+(as.numeric(wellcol)-1)*8)
}

# Exports a dataframe to an excel file. Contains no additional formatting, just the raw data
# Just used for testing
exportDFtoExcel <- function(df,name) {
  
  write.xlsx(df,paste(name,".xlsx",sep=''))
  
}


# Adds a dataframe to a sheet in a workbook
# Copies a sheet starting in cell 1,1, then applies the Excel styles. Shows with a zoom of 75% for readability
#   wb - The workbook object in memory
#   sheet - the String name of the sheet you would like to add
#   df - the dataframe with the data you want to write.

addDataToWB <- function(wb, sheet, df) {
  addWorksheet(wb, sheet, zoom = 75)
  # freezePane(wb, sheet ,  firstActiveRow = 2,  firstActiveCol = 7)
  writeData(wb,sheet,df,startCol=1,startRow=1)
  wb <- applyExcelStyles(wb,df,sheet,1)
}


# Applies a style to a specific sheet 
# Currently shows a blue background with white text for row 1 and column 1
#   wb - workbook to edit
#   df - the dataframe that was added to the workbook
#   dfsheet - the name of the sheet to add the formatting to
#   headerRow - the row number of the column headers
applyExcelStyles <- function(wb,df,dfsheet,headerRow) {
  
  #Create the styles
  headerStyle <- createStyle(textDecoration = "bold", fontColour = "#FFFFFF", fgFill ="#16365C")
  generalStyle <- createStyle(halign= "center", valign = "center", wrapText = TRUE)
  
  nRows <- nrow(df)
  nCols <- ncol(df)
  
  # Weird behavior with the row numbers - row 1 is top row, but sometimes need to start at row 0 for style to apply
  addStyle(wb,dfsheet,generalStyle,rows=0:nRows+1,cols=1:nCols,gridExpand = TRUE, stack = TRUE)
  addStyle(wb,dfsheet,headerStyle,rows=headerRow,cols=1:nCols,gridExpand = TRUE, stack = TRUE)
  addStyle(wb,dfsheet,headerStyle,rows=headerRow:nRows+1,cols=1,gridExpand = TRUE, stack = TRUE)
  setColWidths(wb,dfsheet, cols=c(1,2,3,4,5), widths=c(5.5,6.25,4,7,6))
  setColWidths(wb,dfsheet, cols=5:nCols, widths="auto")
  setRowHeights(wb,dfsheet,rows=0:nRows+1, heights=14)

}


# Imports a CSV into a data frame
# Tolerant to missing lines within the median section - will skip empty lines
# s - rows to skip
# n - max number of rows to read
importCSV <- function(datapath, skip, n) {
  
  csv <- read.csv(datapath, sep=';', header=TRUE, skip=s,nrows=n,dec=",")
  
  return(csv)
  
}

# Calculates the mode of something
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

# Takes data from the SAS1 function and generates a box plot for the bead count data
#   SAS1DF - the data frame from the end of SAS1 (should be allocatedLuminexDF)
getCountGraph <- function(SAS1DF) {
  
  # Must be in long format to show grouped box plots
  wideDF <- SAS1DF
  longDF <- gather(wideDF, key="Beadset",value="Beadcount",contains("count_"), -FortNr)
  longDF[,"Beadset"] <- sub("count", "", longDF[,"Beadset"])
  SAS1plot <- ggplot(data = longDF, mapping = aes(x = Beadset, y = Beadcount, FortNr = FortNr), 
      text = aes_string(x = Beadset, y = Beadcount, FortNr = FortNr)) + geom_boxplot() +
    theme(axis.text.x = element_text(angle = 45, vjust = 0.4, hjust=1)) 
  
  #geom_boxplot(outlier.colour = NA)
  #+   geom_point(data = function(x) dplyr::filter_(x, ~ outlier), position = 'jitter')
  return(SAS1plot)
}

# Takes data from the allocated luminex dataframes and generates a box plot for MFI
#   SASDF - the allocated luminex dataframe (can take input from SAS1 or SAS2)
getMFIgraph <- function(SASDF) {
  
  # Must be in long format to show grouped box plots
  wideDF <- SASDF
  longDF <- gather(wideDF, key="Beadset",value="MFIvalue",contains("mfi_"), -FortNr)
  longDF[,"Beadset"] <- sub("mfi", "", longDF[,"Beadset"])
  SASplot <- ggplot(data = longDF, mapping = aes(x = Beadset, y = MFIvalue)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.4, hjust=1)) + geom_boxplot()
   #+ geom_point(data = function(x) dplyr::filter_(x, ~ outlier), position = 'jitter')
  return(SASplot)
}
  
# Does the same functionality of paste, but will exclude values that have NA, and not add the seperator
# ... - the strings to paste together
# sep - the seperator to use
paste2 <- function(...,sep="; ") {
  L <- list(...)
  L <- lapply(L,function(x) {x[is.na(x)] <- ""; x})
  ret <-gsub(paste0("(^",sep,"|",sep,"$)"),"",
             gsub(paste0(sep,sep),sep,
                  do.call(paste,c(L,list(sep=sep)))))
  is.na(ret) <- ret==""
  ret
}

#Orders a dataframe by the FortNr
orderFortNr <- function(df) {
  
  return(df[order(df$FortNr),])
  
}

# Run the application 
shinyApp(ui = ui, server = server,options = list(height = 1080))